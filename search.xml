<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>图像增强方法</title>
      <link href="2021/04/27/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/"/>
      <url>2021/04/27/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="直方图均衡优化"><a href="#直方图均衡优化" class="headerlink" title="直方图均衡优化"></a>直方图均衡优化</h2><p><img src="https://master2334.github.io/img/inhense.png" alt="av2aar"></p><ul><li>直方图均衡优化是指将一幅已知灰度概率密度分布的图像经过一种变换，将其转变为均衡灰度概率密度分布的新图像。</li><li>直方图均衡优化的步骤：<ul><li>1.计算累计直方图</li><li>2.将累计直方图进行区间转换</li><li>3.在累计直方图中，概率相近的原始值，会被处理为相同的值 </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 研究 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像增强 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新唐控水控雨主机调试过程</title>
      <link href="2021/04/04/%E6%96%B0%E5%94%90%E6%8E%A7%E6%B0%B4%E6%8E%A7%E9%9B%A8%E4%B8%BB%E6%9C%BA%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B/"/>
      <url>2021/04/04/%E6%96%B0%E5%94%90%E6%8E%A7%E6%B0%B4%E6%8E%A7%E9%9B%A8%E4%B8%BB%E6%9C%BA%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="串口接收问题"><a href="#串口接收问题" class="headerlink" title="串口接收问题"></a>串口接收问题</h2><ul><li>使用定义好的USART0接收时一直无法在PC端接收到数据。<ul><li>问题解决。接线错误，对485认识不够。485在通信时只需要接对AB两根线，D+接A，D-接B，共地即可。</li></ul></li><li>串口接收中断。<ul><li>问题解决。直接使用中断中的RX_buffer[]数组会有数据丢失问题，需要使用经过断包处理的UART_in数组来接收。</li></ul></li><li>注意<ul><li>串口连续发送会出现未知数据。 </li></ul></li><li>usart0的UART0_in由于丢包问题需要移位使用。<h2 id="CRC校验问题"><a href="#CRC校验问题" class="headerlink" title="CRC校验问题"></a>CRC校验问题</h2></li><li>本次校验使用CRC16-MODBUS标准。其中校验位低位在前，高位在后。<ul><li>中途出错，因为调用CRC函数时，返回值存储在u8数值中，造成了数据丢失。<h2 id="EEPROM问题"><a href="#EEPROM问题" class="headerlink" title="EEPROM问题"></a>EEPROM问题</h2></li></ul></li><li>在底层库中已经有封装好的EEPROM写入以及读取程序，出错原因是没有拉低写保护。<h2 id="MODBUS-RTU的理解"><a href="#MODBUS-RTU的理解" class="headerlink" title="MODBUS-RTU的理解"></a>MODBUS-RTU的理解</h2></li><li>不理解初始结构/结束结构  大于4字符的时间如何代码实现。</li></ul><h2 id="RS485问题"><a href="#RS485问题" class="headerlink" title="RS485问题"></a>RS485问题</h2><ul><li>485挂载多台设备如何实现。<ul><li>主机发送消息时，所有从机设备都会收到，但是需要将数据地址与自身地址做比较。   从机不能向主机主动发送数据。</li></ul></li><li>由于485采用半双工模式，所以必须采用轮询的方式来获取传感器数据,而且必须一问一答。即向一个传感器发送读取寄存器的指令后，马上读取串口中断接收函数。</li></ul><h2 id="蠕动泵"><a href="#蠕动泵" class="headerlink" title="蠕动泵"></a>蠕动泵</h2><ul><li>使用何种算法。</li></ul><h2 id="控水系统"><a href="#控水系统" class="headerlink" title="控水系统"></a>控水系统</h2><ul><li>用于控水的模糊控制算法</li><li>设置死区； 控水量； 间隔时间；</li></ul><h2 id="控雨系统"><a href="#控雨系统" class="headerlink" title="控雨系统"></a>控雨系统</h2><ul><li>控雨系数为0，不需要向系统供水。</li><li>控雨系数&lt;1，减雨控制</li><li>控雨系数&gt;1,增雨控制               </li><li>通过降雨体积量乘以系数得出供水量，通过蠕动泵向土体供水。</li></ul><h4 id="疑问记录"><a href="#疑问记录" class="headerlink" title="疑问记录"></a>疑问记录</h4><ul><li>从机所控制的传感器地址是否需要留修改的接口。</li><li>多个传感器如何接线。</li><li>传感器的地址如何设定。</li><li>主机向从机发送的代码示例。</li><li>4个传感器的湿度数据是一直读取吗。<pre><code>- 解决 </code></pre></li><li>需要蒸渗仪水分变化的大致区间。</li><li>需要读取的蠕动泵信息。<pre><code>- 暂时取自己需要的 </code></pre></li><li>关于传感器的安装位置，大田水分以及蒸渗仪水分如何取。<pre><code>- 大田水分取了最小值，蒸渗仪水分取了最大值</code></pre></li><li>蠕动泵何时启动关闭</li></ul><h4 id="任务完成度"><a href="#任务完成度" class="headerlink" title="任务完成度"></a>任务完成度</h4><ul><li>把各个串口的RS485接收\发送程序封装好。<ul><li>完成</li></ul></li><li>封装4个读取土壤传感器湿度的函数。<ul><li>完成</li></ul></li><li>蠕动泵指令调试，RS485-MODBUS-RTU  03 06 10指令的测试<ul><li>完成</li></ul></li><li>三串口调试<ul><li>完成</li></ul></li><li>float to 16 C实现<ul><li>完成</li></ul></li><li>一条总线搭载多台设备的测试<ul><li>需要RS485集线器 </li></ul></li><li>EEPROM存储死区，间隔时间以及控水量<ul><li>完成</li></ul></li><li>UART0的主机指令接收分析</li><li>测试连续设置蠕动泵相关参数</li><li>控雨系统控制程序完善</li><li>水位传感器的操作逻辑</li><li>死区之类的控制参数需要设置吗</li></ul>]]></content>
      
      
      <categories>
          
          <category> 调试经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 新唐NUC126系列 </tag>
            
            <tag> MODBUS-RTU </tag>
            
            <tag> Fuzzy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java实例之字符串</title>
      <link href="2021/03/20/java%E5%AE%9E%E4%BE%8B%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
      <url>2021/03/20/java%E5%AE%9E%E4%BE%8B%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<h3 id="1-字符串比较"><a href="#1-字符串比较" class="headerlink" title="1. 字符串比较"></a>1. 字符串比较</h3><ul><li><p>调用String类的<code>.compareTo(string)</code>, <code>.compareToIgnoreCase(string)``, compareTo(object string)</code>,返回第一个字母的ASCII差值。</p><pre><code class="java">public class StringCompareEmp&#123; public static void main(String args[])&#123;    String str = &quot;Hello World&quot;;    String anotherString = &quot;hello world&quot;;    Object objStr = str;    System.out.println( str.compareTo(anotherString) );//  print -32    System.out.println( str.compareToIgnoreCase(anotherString) );  //忽略大小写 print 0    System.out.println( str.compareTo(objStr.toString()));// print 0 &#125;&#125;</code></pre></li></ul><h3 id="2-查找字符串最后一次出现的位置"><a href="#2-查找字符串最后一次出现的位置" class="headerlink" title="2. 查找字符串最后一次出现的位置"></a>2. 查找字符串最后一次出现的位置</h3><ul><li>通过调用String类的 <code>str.lastIndexOf(&#39; &#39;)</code>,返回第一次出现该字段的索引值。<pre><code class="java">public class SearchlastString &#123; public static void main(String[] args) &#123;    String strOrig = &quot;Hello world ,Hello Runoob&quot;;    int lastIndex = strOrig.lastIndexOf(&quot;Runoob&quot;);    if(lastIndex == - 1)&#123;       System.out.println(&quot;没有找到字符串 Runoob&quot;);    &#125;else&#123;       System.out.println(&quot;Runoob 字符串最后出现的位置： &quot;+ lastIndex);    &#125; &#125;&#125;</code></pre></li></ul><h3 id="3-删除字符串中的一个字符"><a href="#3-删除字符串中的一个字符" class="headerlink" title="3. 删除字符串中的一个字符"></a>3. 删除字符串中的一个字符</h3><ul><li>通过两次调用String类的<code>str.substring(pos1,pos2)</code>来实现字符串的截取。<pre><code class="java">public class Main &#123; public static void main(String args[]) &#123;    String str = &quot;this is Java&quot;;    System.out.println(removeCharAt(str, 3)); &#125; public static String removeCharAt(String s, int pos) &#123;    return s.substring(0, pos) + s.substring(pos + 1); &#125;&#125;</code></pre></li></ul><h3 id="4-字符串替换"><a href="#4-字符串替换" class="headerlink" title="4. 字符串替换"></a>4. 字符串替换</h3><ul><li>通过调用String类的indexOf()的<code>str.replace()</code>来对字符串进行替换。<pre><code class="java">public class StringReplaceEmp&#123; public static void main(String args[])&#123;    String str=&quot;Hello World&quot;;    System.out.println( str.replace( &#39;H&#39;,&#39;W&#39; ) );    System.out.println( str.replaceFirst(&quot;He&quot;, &quot;Wa&quot;) );    System.out.println( str.replaceAll(&quot;He&quot;, &quot;Ha&quot;) ); &#125;&#125;</code></pre></li></ul><h3 id="5-字符串反转"><a href="#5-字符串反转" class="headerlink" title="5.字符串反转"></a>5.字符串反转</h3><pre><code class="java">public class StringReverseExample&#123;   public static void main(String[] args)&#123;      String string=&quot;runoob&quot;;      String reverse = new StringBuffer(string).reverse().toString();      System.out.println(&quot;字符串反转前:&quot;+string);      System.out.println(&quot;字符串反转后:&quot;+reverse);   &#125;&#125;</code></pre><h3 id="6-字符串搜索"><a href="#6-字符串搜索" class="headerlink" title="6. 字符串搜索"></a>6. 字符串搜索</h3><ul><li>通过调用String类的<code>str.indexOf(&#39; &#39;)</code>，查找出现该字段的位置，返回第一个字母的索引值，返回值为-1则查找失败。<pre><code class="java">public class SearchStringEmp &#123; public static void main(String[] args) &#123;    String strOrig = &quot;Google Runoob Taobao&quot;;    int intIndex = strOrig.indexOf(&quot;Runoob&quot;);    if(intIndex == - 1)&#123;       System.out.println(&quot;没有找到字符串 Runoob&quot;);    &#125;else&#123;       System.out.println(&quot;Runoob 字符串位置 &quot; + intIndex);    &#125; &#125;&#125;</code></pre></li></ul><h3 id="7-字符串分割"><a href="#7-字符串分割" class="headerlink" title="7. 字符串分割"></a>7. 字符串分割</h3><pre><code class="java">public class JavaStringSplitEmp &#123;   public static void main(String args[])&#123;      String str = &quot;www-runoob-com&quot;;      String[] temp;      String delimeter = &quot;-&quot;;  // 指定分割字符      temp = str.split(delimeter); // 分割字符串      // 普通 for 循环      for(int i =0; i &lt; temp.length ; i++)&#123;         System.out.println(temp[i]);         System.out.println(&quot;&quot;);      &#125;      System.out.println(&quot;------java for each循环输出的方法-----&quot;);      String str1 = &quot;www.runoob.com&quot;;      String[] temp1;      String delimeter1 = &quot;\\.&quot;;  // 指定分割字符， . 号需要转义      temp1 = str1.split(delimeter1); // 分割字符串      for(String x :  temp1)&#123;         System.out.println(x);         System.out.println(&quot;&quot;);      &#125;   &#125;&#125;</code></pre><h3 id="8-字符串分割"><a href="#8-字符串分割" class="headerlink" title="8. 字符串分割"></a>8. 字符串分割</h3><ul><li><p>调用String类的<code>str.split()</code>方法，返回值存储在<code>String[]</code>中。</p><pre><code class="java">public class JavaStringSplitEmp &#123; public static void main(String args[])&#123;    String str = &quot;www-runoob-com&quot;;    String[] temp;    String delimeter = &quot;-&quot;;  // 指定分割字符    temp = str.split(delimeter); // 分割字符串    // 普通 for 循环    for(int i =0; i &lt; temp.length ; i++)&#123;       System.out.println(temp[i]);       System.out.println(&quot;&quot;);    &#125;    System.out.println(&quot;------java for each循环输出的方法-----&quot;);    String str1 = &quot;www.runoob.com&quot;;    String[] temp1;    String delimeter1 = &quot;\\.&quot;;  // 指定分割字符， . 号需要转义    temp1 = str1.split(delimeter1); // 分割字符串    for(String x :  temp1)&#123;       System.out.println(x);       System.out.println(&quot;&quot;);    &#125; &#125;&#125;</code></pre><h3 id="9-字符串大写转小写"><a href="#9-字符串大写转小写" class="headerlink" title="9. 字符串大写转小写"></a>9. 字符串大写转小写</h3></li><li><p>String类的<code>str.toUpperCase()</code>;</p><pre><code class="java">public class StringToUpperCaseEmp &#123;  public static void main(String[] args) &#123;      String str = &quot;string runoob&quot;;      String strUpper = str.toUpperCase();      System.out.println(&quot;原始字符串: &quot; + str);      System.out.println(&quot;转换为大写: &quot; + strUpper);  &#125;&#125;</code></pre></li></ul><h3 id="10-测试两个字符串区域是否相等"><a href="#10-测试两个字符串区域是否相等" class="headerlink" title="10. 测试两个字符串区域是否相等"></a>10. 测试两个字符串区域是否相等</h3><pre><code class="java">public class StringRegionMatch&#123;   public static void main(String[] args)&#123;      String first_str = &quot;Welcome to Microsoft&quot;;      String second_str = &quot;I work with microsoft&quot;;      boolean match1 = first_str.      regionMatches(11, second_str, 12, 9);      boolean match2 = first_str.      regionMatches(true, 11, second_str, 12, 9); //第一个参数 true 表示忽略大小写区别      System.out.println(&quot;区分大小写返回值：&quot; + match1);      System.out.println(&quot;不区分大小写返回值：&quot; + match2);   &#125;&#125;</code></pre><h3 id="11-字符串性能比较测试"><a href="#11-字符串性能比较测试" class="headerlink" title="11. 字符串性能比较测试"></a>11. 字符串性能比较测试</h3><pre><code class="java">public class StringComparePerformance&#123;   public static void main(String[] args)&#123;            long startTime = System.currentTimeMillis();      for(int i=0;i&lt;50000;i++)&#123;         String s1 = &quot;hello&quot;;         String s2 = &quot;hello&quot;;      &#125;      long endTime = System.currentTimeMillis();      System.out.println(&quot;通过 String 关键词创建字符串&quot;       + &quot; : &quot;+ (endTime - startTime)       + &quot; 毫秒&quot; );             long startTime1 = System.currentTimeMillis();      for(int i=0;i&lt;50000;i++)&#123;         String s3 = new String(&quot;hello&quot;);         String s4 = new String(&quot;hello&quot;);      &#125;      long endTime1 = System.currentTimeMillis();      System.out.println(&quot;通过 String 对象创建字符串&quot;       + &quot; : &quot; + (endTime1 - startTime1)      + &quot; 毫秒&quot;);   &#125;&#125;</code></pre><h3 id="12-字符串优化"><a href="#12-字符串优化" class="headerlink" title="12. 字符串优化"></a>12. 字符串优化</h3><pre><code class="java">public class StringOptimization &#123;    public static void main(String[] args)&#123;        String variables[] = new String[50000];              for( int i=0;i &lt;50000;i++)&#123;            variables[i] = &quot;s&quot;+i;        &#125;        long startTime0 = System.currentTimeMillis();        for(int i=0;i&lt;50000;i++)&#123;            variables[i] = &quot;hello&quot;;        &#125;        long endTime0 = System.currentTimeMillis();        System.out.println(&quot;直接使用字符串： &quot;+ (endTime0 - startTime0)  + &quot; ms&quot; );        long startTime1 = System.currentTimeMillis();            for(int i=0;i&lt;50000;i++)&#123;            variables[i] = new String(&quot;hello&quot;);        &#125;        long endTime1 = System.currentTimeMillis();        System.out.println(&quot;使用 new 关键字：&quot; + (endTime1 - startTime1) + &quot; ms&quot;);        long startTime2 = System.currentTimeMillis();        for(int i=0;i&lt;50000;i++)&#123;            variables[i] = new String(&quot;hello&quot;);            variables[i] = variables[i].intern();                  &#125;        long endTime2 = System.currentTimeMillis();        System.out.println(&quot;使用字符串对象的 intern() 方法: &quot;         + (endTime2 - startTime2)        + &quot; ms&quot;);    &#125;&#125;</code></pre><h3 id="13-字符串格式化"><a href="#13-字符串格式化" class="headerlink" title="13. 字符串格式化"></a>13. 字符串格式化</h3><pre><code class="java">import java.util.*;public class StringFormat &#123;    public static void main(String[] args)&#123;        double e = Math.E;        System.out.format(&quot;%f%n&quot;, e);        System.out.format(Locale.CHINA  , &quot;%-10.4f%n%n&quot;, e);  //指定本地为中国（CHINA）    &#125;&#125;</code></pre><h3 id="14-连接字符串"><a href="#14-连接字符串" class="headerlink" title="14.连接字符串"></a>14.连接字符串</h3><pre><code class="java">public class StringConcatenate &#123;    public static void main(String[] args)&#123;        long startTime = System.currentTimeMillis();        for(int i=0;i&lt;5000;i++)&#123;            String result = &quot;This is&quot;            + &quot;testing the&quot;            + &quot;difference&quot;+ &quot;between&quot;            + &quot;String&quot;+ &quot;and&quot;+ &quot;StringBuffer&quot;;        &#125;        long endTime = System.currentTimeMillis();        System.out.println(&quot;字符串连接&quot;         + &quot; - 使用 + 操作符 : &quot;         + (endTime - startTime)+ &quot; ms&quot;);        long startTime1 = System.currentTimeMillis();        for(int i=0;i&lt;5000;i++)&#123;            StringBuffer result = new StringBuffer();            result.append(&quot;This is&quot;);            result.append(&quot;testing the&quot;);            result.append(&quot;difference&quot;);            result.append(&quot;between&quot;);            result.append(&quot;String&quot;);            result.append(&quot;and&quot;);            result.append(&quot;StringBuffer&quot;);        &#125;        long endTime1 = System.currentTimeMillis();        System.out.println(&quot;字符串连接&quot;         + &quot; - 使用 StringBuffer : &quot;        + (endTime1 - startTime1)+ &quot; ms&quot;);    &#125;&#125;</code></pre><ul><li><code>String.format()</code> 创建格式化字符串而不输出</li></ul>]]></content>
      
      
      <categories>
          
          <category> 程序资料 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Gym-Reinforcement-FrozenLake</title>
      <link href="2021/03/01/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8BFrozenLake/"/>
      <url>2021/03/01/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8BFrozenLake/</url>
      
        <content type="html"><![CDATA[<ul><li>使用Open-AI中的gym库创建环境。<pre><code class="python">import torchimport timeimport matplotlib.pyplot as pltfrom gym.envs.registration import registerimport gymregister(  id=&#39;FrozenLakeNotSlippery-v0&#39;,  entry_point=&#39;gym.envs.toy_text:FrozenLakeEnv&#39;,  kwargs=&#123;&#39;map_name&#39; : &#39;4x4&#39;, &#39;is_slippery&#39;: False&#125;,)plt.ion() #plt默认为阻塞模式，.ion为解除阻塞env = gym.make(&#39;FrozenLakeNotSlippery-v0&#39;)#创建环境env.render() #加载图像引擎</code></pre></li><li>确定好需要使用的参数值。<pre><code class="python">number_of_states = env.observation_space.nnumber_of_actions = env.action_space.nprint( &quot;States = &quot;, number_of_states)print( &quot;Actions = &quot;, number_of_actions)num_episodes = 1000steps_total = []rewards_total = []egreedy_total = []gamma = 0.95  # 未来行为最大化收益的期望占比learning_rate = 0.9   #学习率egreedy = 0.7  #贪婪率    值越低，代表经验占比越高egreedy_final = 0.1egreedy_decay = 0.999Q = torch.zeros([number_of_states, number_of_actions])   #创建一个新的Q值矩阵</code></pre></li><li>本段代码的意图为首先根据贪婪率确定下一步的行为，然后把行为赋值到环境中，获得新的环境以及行为状态。</li><li>获得新的Q值矩阵。</li><li>获得新的状态，行为信息。<pre><code class="python">for i_episode in range(num_episodes):  # 重置环境  state = env.reset()  step = 0  while True:      step += 1      random_for_egreedy = torch.rand(1)[0]      if random_for_egreedy &gt; egreedy:                random_values = Q[state] + torch.rand(1,number_of_actions) / 1000                action = torch.max(random_values,1)[1][0]            #torch.max(tensor, dim)  dim是索引的维度  0是每列的最大值，1是每行的最大值          #函数会返回两个tensor，第一个tensor是每行的最大值，softmax的输出中最大的是1，所以第一个tensor是全1的tensor；第二个tensor是每行最大值的索引。          action = action.item()      else:          action = env.action_space.sample()      if egreedy &gt; egreedy_final:          egreedy *= egreedy_decay      new_state, reward, done, info = env.step(action)      # Filling the Q Table      Q[state, action] = reward + gamma * torch.max(Q[new_state])      # Setting new state for next action      state = new_state      # env.render()      # time.sleep(0.4)      if done:          steps_total.append(step)          rewards_total.append(reward)          egreedy_total.append(egreedy)          if i_episode % 10 == 0:              print(&#39;Episode: &#123;&#125; Reward: &#123;&#125; Steps Taken: &#123;&#125;&#39;.format(i_episode,reward, step))          break</code></pre></li><li>在plt中显示rewards，steps，egreedy的变化曲线<pre><code class="python">print(&quot;Percent of episodes finished successfully: &#123;0&#125;&quot;.format(sum(rewards_total)/num_episodes))print(&quot;Percent of episodes finished successfully (last 100 episodes): &#123;0&#125;&quot;.format(sum(rewards_total[-100:])/100))print(&quot;Average number of steps: %.2f&quot; % (sum(steps_total)/num_episodes))print(&quot;Average number of steps (last 100 episodes): %.2f&quot; % (sum(steps_total[-100:])/100))plt.figure(figsize=(6,3))plt.title(&quot;Rewards&quot;)plt.bar(torch.arange(len(rewards_total)), rewards_total, alpha=0.6, color=&#39;green&#39;, width=5)plt.show()plt.figure(figsize=(6,3))plt.title(&quot;Steps / Episode length&quot;)plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color=&#39;red&#39;, width=5)plt.show()plt.figure(figsize=(6,3))plt.title(&quot;Egreedy value&quot;)plt.bar(torch.arange(len(egreedy_total)), egreedy_total, alpha=0.6, color=&#39;blue&#39;, width=5)plt.ioff()plt.show()</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 程序经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> Q-Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/01/21/git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>2021/01/21/git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h1 id="vscode与github远程仓库的连接"><a href="#vscode与github远程仓库的连接" class="headerlink" title="vscode与github远程仓库的连接"></a>vscode与github远程仓库的连接</h1><ul><li>先在github上建立新的仓库<ul><li>出现fatal: not a git repository (or any of the parent directories): .git， 则是缺少.git文件 输入git init 即可解决</li></ul></li><li>git remote add github + http链接</li><li>分支状态可在左下角查看</li><li>git checkout 切换分支<h1 id="vscode-直接下载github项目"><a href="#vscode-直接下载github项目" class="headerlink" title="vscode 直接下载github项目"></a>vscode 直接下载github项目</h1></li><li>复制需要下载的github仓库链接</li><li>切换到目标目录</li><li>vscode终端输入git clone + url</li><li></li></ul><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><p>git fetch</p><h1 id="hexo-io"><a href="#hexo-io" class="headerlink" title="hexo.io"></a>hexo.io</h1><ul><li>博客格式设置时，在_config.yml里找到对应项目进行修改<br>hexo g -d </li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Python爬取疫情实时数据</title>
      <link href="2021/01/18/Python%E7%88%AC%E5%8F%96%E7%96%AB%E6%83%85%E6%95%B0%E6%8D%AE/"/>
      <url>2021/01/18/Python%E7%88%AC%E5%8F%96%E7%96%AB%E6%83%85%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="用python爬取疫情数据网站的实时数据流"><a href="#用python爬取疫情数据网站的实时数据流" class="headerlink" title="用python爬取疫情数据网站的实时数据流"></a>用python爬取疫情数据网站的实时数据流</h2><p>一些网站的数据并没有写在html源码中，而是通过数据流实时获取的，因此需要在F12中找到数据流的JSON文件，通过解析JSON文件来获取自己想要的信息。<br>此程序的功能是通过<code>json.loads()</code>解析json源文件，然后将json源文件保存在txt文件以及数据库中。</p><pre><code class="python">import requestsfrom bs4 import BeautifulSoupfrom fake_useragent import UserAgentimport json, jsonpathimport sqlite3url = &#39;https://api.inews.qq.com/newsqa/v1/query/inner/publish/modules/list?modules=chinaDayList,chinaDayAddList,nowConfirmStatis,provinceCompare&#39;conn = sqlite3.connect(&#39;.\YQdata.db&#39;)c = conn.cursor()c.execute(&#39;&#39;&#39;CREATE TABLE IF NOT EXISTS datas             (Province text, nowConfirm text, confirmAdd text, dead text, heal text)&#39;&#39;&#39;)#requests.session() 会话保持，可以让我们在跨请求时保存某些操作#在爬虫中，需要用到session来保持登录状态，一些网站会要求强制登陆，登录信息不完整时，返回的数据信息也不完整session = requests.session()result = session.get(url)#json.loads()  将json格式解析为dict格式  #json.dumps()  将dict格式解析为json格式resJson = json.loads(result.text)data = jsonpath.jsonpath(resJson, &#39;$.data.chinaDayAddList.*&#39;)for d in data:    #res为字符串格式的拼接   d[&#39;date&#39;]为字典键值的引用    res = &#39;日期:&#39; + d[&#39;date&#39;] + &#39;--&#39; + &#39;新增确诊:&#39; + str(d[&#39;confirm&#39;]) + &#39;--&#39; + &#39;死亡人数:&#39; + str(d[&#39;dead&#39;]) + &#39;--&#39; + &#39;感染人数:&#39; + str(d[&#39;infect&#39;])+ &#39;--&#39; + &#39;治愈人数:&#39; + str(d[&#39;heal&#39;])    # 保存数据到指定路径    file = &#39;.\global-yq.txt&#39;    with open(file, &#39;a+&#39;,encoding=&#39;utf-8&#39;) as f:        f.write(res + &#39;\n&#39;)  # 加\n换行显示data2 = jsonpath.jsonpath(resJson, &#39;$.data.provinceCompare.&#39;)# 字典格式的常用方法# for k in data2[0].values():#     print(data2[0][k])#使用zip方法，将两个list同时迭代for (key, value) in zip(data2[0].keys(), data2[0].values()):   # print(value)    com = &quot;INSERT INTO datas VALUES (?,?,?,?,?)&quot;    c.execute(com,tuple((str(key),value[&#39;nowConfirm&#39;],value[&#39;confirmAdd&#39;],value[&#39;dead&#39;],value[&#39;heal&#39;])))    res =  str(key) + &#39;--&#39; + &#39;新增确诊:&#39; + str(value[&#39;nowConfirm&#39;])  + &#39;--&#39; + &#39;无症状感染者:&#39; + str(value[&#39;confirmAdd&#39;]) + &#39;--&#39; +  &#39;死亡人数:&#39; + str(value[&#39;dead&#39;]) + &#39;--&#39; +  &#39;治愈人数:&#39; + str(value[&#39;heal&#39;])    # 保存数据到我的d盘    file = &#39;.\china-yq.txt&#39;    with open(file, &#39;a+&#39;,encoding=&#39;utf-8&#39;) as f:        f.write(res + &#39;\n&#39;)  # 加\n换行显示conn.commit()conn.close()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 程序经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 实时数据流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络应用之DogVSCats</title>
      <link href="2021/01/16/DogVSCats%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/"/>
      <url>2021/01/16/DogVSCats%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h1 id="迁移学习-VGGNet、VGG16、ResNet50"><a href="#迁移学习-VGGNet、VGG16、ResNet50" class="headerlink" title="迁移学习 VGGNet、VGG16、ResNet50"></a>迁移学习 VGGNet、VGG16、ResNet50</h1><p>按照下载好的数据集运行时,会出现如下错误：</p><pre><code class="python">RuntimeError: Found 0 files in subfolders of: ./DogsVSCats/validSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp</code></pre><p>此时需要按照image/image/picture的排列方式，新建文件夹。</p><pre><code class="python">data_dir = &quot;./DogsVSCats/&quot;</code></pre><p>import torch<br>import torchvision<br>from torchvision import datasets,transforms<br>import os<br>import matplotlib.pyplot as plt<br>import time</p><h1 id="data-dir-os-getcwd"><a href="#data-dir-os-getcwd" class="headerlink" title="data_dir = os.getcwd()"></a>data_dir = os.getcwd()</h1><h1 id="data-dir-os-path-join-data-dir-”DogsVSCats”"><a href="#data-dir-os-path-join-data-dir-”DogsVSCats”" class="headerlink" title="data_dir = os.path.join(data_dir,”DogsVSCats”)"></a>data_dir = os.path.join(data_dir,”DogsVSCats”)</h1><p>data_dir = “./DogsVSCats/“</p><p>data_transform = {<br>    x:transforms.Compose(<br>        [<br>            transforms.Scale([64,64]),    #Scale类将原始图片的大小统一缩放至64×64<br>            transforms.ToTensor()<br>        ]<br>    )<br>    for x in [“train”,”valid”]<br>}</p><p>image_datasets = {<br>    x:datasets.ImageFolder(<br>        root=os.path.join(data_dir,x),<br>        #将输入参数中的两个名字拼接成一个完整的文件路径<br>        transform=data_transform[x]<br>    )<br>    for x in [“train”,”valid”]<br>}</p><p>dataloader = {<br>    x:torch.utils.data.DataLoader(<br>        dataset=image_datasets[x],<br>        batch_size=16,<br>        shuffle=True<br>    )<br>    for x in [“train”,”valid”]<br>}</p><p>X_example, Y_example = next(iter(dataloader[‘train’]))<br>print(‘X_example个数{}’.format(len(X_example)))   #X_example个数16<br>print(‘Y_example个数{}’.format(len(Y_example)))   #Y_example个数16</p><p>index_classes = image_datasets[‘train’].class_to_idx   # 显示类别对应的独热编码<br>print(index_classes)     #{‘cat’: 0, ‘dog’: 1}</p><p>example_classes = image_datasets[‘train’].classes     # 将原始图像的类别保存起来<br>print(example_classes)       #[‘cat’, ‘dog’]</p><p>img = torchvision.utils.make_grid(X_example)<br>img = img.numpy().transpose([1,2,0])<br>print([example_classes[i] for i in Y_example])<br>#[‘cat’, ‘cat’, ‘cat’, ‘cat’, ‘dog’, ‘cat’, ‘cat’, ‘dog’, ‘cat’, ‘cat’, ‘dog’, ‘dog’, ‘cat’, ‘dog’, ‘dog’, ‘cat’]<br>plt.imshow(img)<br>plt.show()</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 猫狗大战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记</title>
      <link href="2021/01/12/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2021/01/12/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="repeat-和expand-区别"><a href="#repeat-和expand-区别" class="headerlink" title="repeat()和expand() 区别"></a>repeat()和expand() 区别</h2><p>torch.Tensor()是包含一种数据类型元素的多维矩阵。<br>torch.Tensor()有两种方法可以用来拓展某维数据的尺寸，分别是expand()和repeat():</p><h3 id="expand"><a href="#expand" class="headerlink" title="expand()"></a>expand()</h3><p>返回当前张量在某维扩展后更大的张量。扩展张量不会分配新的内存，只是在当前存在的张量上创建新的视图，一个大小等于1的维度扩展到更大的尺寸。</p><h3 id="repeat"><a href="#repeat" class="headerlink" title="repeat()"></a>repeat()</h3>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lenet网络：手写数字检测</title>
      <link href="2021/01/11/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
      <url>2021/01/11/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><pre><code class="python">import matplotlib.pyplot as pltimport numpy as npimport cv2import timeimport torch# torchvision包的主要功能是实现数据的处理，导入和预览等import torchvisionfrom torchvision import datasetsfrom torchvision import transformsfrom torch.autograd import Variablestart_time = time.time()# 对数据进行载入及有相应变换,将Compose看成一种容器，他能对多种数据变换进行组合# 传入的参数是一个列表，列表中的元素就是对载入的数据进行的各种变换操作transform = transforms.Compose([transforms.ToTensor(),                                transforms.Normalize(mean=[0.5],std=[0.5])])# 首先获取手写数字的训练集和测试集# datasets 的功能是设置数据集# root 用于指定数据集在下载之后的存放路径# transform 用于指定导入数据集需要对数据进行那种变化操作# train是指定在数据集下载完成后需要载入那部分数据，# 如果设置为True 则说明载入的是该数据集的训练集部分# 如果设置为FALSE 则说明载入的是该数据集的测试集部分data_train = datasets.MNIST(root=&quot;./data/&quot;,                           transform = transform,                            train = True,                            download = True)data_test = datasets.MNIST(root=&quot;./data/&quot;,                           transform = transform,                            train = False)# data_test的本质是一个可迭代的Dataloader，使用next方法调用出其中一个对象# shape的功能是输出矩阵的大小# print(next(iter(data_test))[0].shape)# 数据预览和数据装载# 下面对数据进行装载，我们可以将数据的载入理解为对图片的处理，# 在处理完成后，我们就需要将这些图片打包好送给我们的模型进行训练了  而装载就是这个打包的过程# dataset 参数用于指定我们载入的数据集名称# batch_size参数是随机从数据集中选取N个图片进行提取，装载在loader中#  在装载的过程会将数据随机打乱顺序并进行打包data_loader_train = torch.utils.data.DataLoader(dataset =data_train,                                                batch_size = 64,                                                shuffle = True)data_loader_test = torch.utils.data.DataLoader(dataset =data_test,                                                batch_size = 64,                                                shuffle = True)# data_loader_train中的两个元组元素是图片、标记值，所以 data_loader_train的图片数量由以下方法调用# print(len((next(iter(data_loader_train)))[0]))# 在装载完成后，我们可以选取其中一个批次的数据进行预览images,labels = next(iter(data_loader_train))img = torchvision.utils.make_grid(images)# transpose方法是转变数组的顺序  0，1，2 变为 1, 2, 0img = img.numpy().transpose(1,2,0)std = [0.5]mean = [0.5]img = img*std +mean# print(labels)#print([labels[i] for i in range(64)])# 由于matplotlab中的展示图片无法显示，所以现在使用OpenCV中显示图片# plt.imshow(img)# cv2.imshow(&#39;win&#39;,img)# key_pressed=cv2.waitKey(0)#模型搭建和参数优化# 在顺利完成数据装载后，我们可以开始编写卷积神经网络模型的搭建和参数优化的代码#卷积层使用torch.nn.Conv2d类来搭建# 激活层使用torch.nn.ReLU 类方法来搭建# 池化层使用torch.nn.MaxPool2d类方法来搭建# 全连接层使用 torch.nn.Linear 类方法来搭建class Model(torch.nn.Module):    def __init__(self):        super(Model,self).__init__()        self.conv1 = torch.nn.Sequential(            # 1是输入通道数   32是输出通道数，在本例中最大为64            torch.nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),            torch.nn.ReLU(),            torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),            torch.nn.ReLU(),            torch.nn.MaxPool2d(stride=2,kernel_size=2))        self.dense = torch.nn.Sequential(            # Linear用于设置全连接层参数            torch.nn.Linear(14*14*64,1024),            torch.nn.ReLU(),            # 用于避免过拟合问题，下一层神经元随机按概率选择            torch.nn.Dropout(p = 0.5),            torch.nn.Linear(1024,10)        )    # 我们通过继承torch.nn.Modeule来构造网络，因为手写数字    # 识别比较简单，我们只是用了两个卷积层，一个最大池化层，两个全连接层。    # 在向前传播过程中进行x.view(-1, 14 * 14 * 128)    # 对参数实现扁平化。最后通过自己self.dense定义的全连接层进行最后的分类    def forward(self, x):        x = self.conv1(x)        x = x.view(-1,14*14*64)        x = self.dense(x)        return x# 在编写完搭建卷积神经网络模型的代码后，我们可以对模型进行训练和参数进行优化了# 首先 定义在训练之前使用哪种损失函数和优化函数# 下面定义了计算损失值的损失函数使用的是交叉熵# 优化函数使用的额是Adam自适应优化算法model = Model()# 将所有的模型参数移动到GPU上if torch.cuda.is_available():    model.cuda()cost = torch.nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters())# print(model)# 卷积神经网络模型进行模型训练和参数优化的代码n_epochs = 5for epoch in range(n_epochs):    running_loss = 0.0    running_correct = 0    print(&quot;Epoch  &#123;&#125;/&#123;&#125;&quot;.format(epoch, n_epochs))    print(&quot;-&quot;*10)    for data in data_loader_train:        X_train , y_train = data        # 有GPU加下面这行，没有不用加        X_train, y_train = X_train.cuda(), y_train.cuda()        X_train , y_train = Variable(X_train),Variable(y_train)        # print(y_train)        outputs = model(X_train)        # print(outputs)        _,pred = torch.max(outputs.data,1)        optimizer.zero_grad()        loss = cost(outputs,y_train)        loss.backward()        optimizer.step()        # running_loss += loss.data[0]        running_loss += loss.item()        running_correct += torch.sum(pred == y_train.data)        # print(&quot;ok&quot;)        # print(&quot;**************%s&quot;%running_corrrect)    print(&quot;train ok &quot;)    testing_correct = 0    for data in data_loader_test:        X_test,y_test = data        # 有GPU加下面这行，没有不用加        X_test, y_test = X_test.cuda(), y_test.cuda()        X_test,y_test = Variable(X_test),Variable(y_test)        outputs = model(X_test)        _, pred = torch.max(outputs,1)        testing_correct += torch.sum(pred == y_test.data)        # print(testing_correct)    print( &quot;Loss is :&#123;:.4f&#125;,Train Accuracy is:&#123;:.4f&#125;%,Test Accuracy is:&#123;:.4f&#125;&quot;.format(                 running_loss / len(data_train),100 * running_correct / len(data_train),                 100 * testing_correct / len(data_test)))stop_time = time.time()print(&quot;time is %s&quot; %(stop_time-start_time))</code></pre>]]></content>
      
      
      <categories>
          
          <category> 程序经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3*3卷积核 </tag>
            
            <tag> 2层卷积网络 </tag>
            
            <tag> 1层2*2池化层 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git以及Hexo博客使用经验</title>
      <link href="2021/01/11/GitHub%E7%9B%B8%E5%85%B3%E7%BB%8F%E9%AA%8C/"/>
      <url>2021/01/11/GitHub%E7%9B%B8%E5%85%B3%E7%BB%8F%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="Github-Pages-Hexo搭建个人网站"><a href="#Github-Pages-Hexo搭建个人网站" class="headerlink" title="Github Pages + Hexo搭建个人网站"></a>Github Pages + Hexo搭建个人网站</h2><ol><li>GitHub Pages和Hexo的介绍  <ul><li>GitHub： Pages 是用来托管Github上静态网页的免费站点  </li><li>Hexo：hexo是一个简单快速强大的静态博客框架  </li></ul></li><li>安装Node.js、Git、Hexo  </li><li>进行Hexo的初始化配置</li><li>在github中创建github.io远程仓库</li><li>将本地的Hexo文件更新到Github库中  <ul><li>在_config.yml文件中修改repository，添加远程链接  </li><li><code>ssh-keygen -t rsa -C email@email.com</code>  </li><li>测试是否成功：<code>ssh -T git@github.com</code>  </li></ul></li><li>将本地的Hexo文件更新到Github库中<ul><li>在_config.yml文件中修改repository，添加远程链接</li></ul></li><li>之后每次提交时，进行<code>git add *</code>操作将文件添加至暂存区，然后<code>git commit -m &quot;name&quot;</code>将文件添加至发送区，之后就可以通过<code>hexo d -g</code>将本次修改同步到博客中</li></ol><h2 id="连接本地仓库与github远程仓库"><a href="#连接本地仓库与github远程仓库" class="headerlink" title="连接本地仓库与github远程仓库"></a>连接本地仓库与github远程仓库</h2><ol><li>终端输入<code>git init </code>,初始化git配置</li><li>首次使用git bash时，需要git config配置个人信息<ul><li><code>git config --global user.name &quot;用户名&quot;</code></li><li><code>git config --global user.mail 邮箱@163.com</code></li></ul></li><li>上传代码至暂存区 <ul><li><code>git add *</code>  提交所有文件至暂存区</li><li><code>git add 文件名</code> 提交当前文件</li><li><code>git commit -m &quot;提交说明&quot;</code>  提交文件至本地仓库</li></ul></li><li>过程中可以使用指令来查看当前状态<ul><li><code>git status</code> 查看当前操作状态</li><li><code>git log</code>   查看提交记录</li><li><code>git diff</code> 查看工作区与暂存区的差异</li><li><code>git reflog</code> 查看历史提交信息以及版本号<ul><li>可以根据指针来查看当前版本位置</li></ul></li><li><code>git reset --hard 版本号</code> 回退历史版本（版本穿梭）</li></ul></li><li>创建分支<ul><li><code>git branch name</code> 创建新的分支</li><li><code>git branch -v</code>  查看分支状态</li><li><code>git checkout name</code> 切换分支</li><li><code>git merge name</code> 合并分支</li><li><code>git branch -d name</code> 删除分支</li><li>每次在切换分支前，提交当前分支</li></ul></li><li>提交至远程仓库<ul><li>git push github main:main</li></ul></li><li>操作结束 </li></ol><h2 id="从远程仓库拉取项目到本地"><a href="#从远程仓库拉取项目到本地" class="headerlink" title="从远程仓库拉取项目到本地"></a>从远程仓库拉取项目到本地</h2><ul><li>本地需要初始化仓储</li><li><code>git pull + 远程仓库链接</code></li></ul><h2 id="从远程仓库克隆项目到本地"><a href="#从远程仓库克隆项目到本地" class="headerlink" title="从远程仓库克隆项目到本地"></a>从远程仓库克隆项目到本地</h2><ul><li><code>git clone + 远程仓库链接</code></li><li>pull和clone一样，一般常使用pull，<code>pull只会做相应的合并，而多次使用clone会覆盖本地内容</code></li></ul>]]></content>
      
      
      <categories>
          
          <category> 软件使用经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 远程仓库 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络基础</title>
      <link href="2021/01/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
      <url>2021/01/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="第二章-人工神经网络基础"><a href="#第二章-人工神经网络基础" class="headerlink" title="第二章 人工神经网络基础"></a>第二章 人工神经网络基础</h2><ol><li>神经元是脑组织的基本单元，近860亿个。</li><li>神经网络的组成：生物科学，大数据，超算，纳米科技。</li><li>生物神经元由4部分组成：细胞体，轴突，树突，突触。</li><li>生物信号传输过程：<ul><li>信号传输通过化学信号</li><li>达到阈值标注，发射信号</li><li>突触来控制信号抑制还是传输</li></ul></li><li>生物神经网络中各个神经元之间连接的强弱按照外<br>部的激励信号作<strong>自适应</strong>变化，每个神经元随着接收<br>到的多个激励信号而得到的综合结果呈现出<strong>兴奋或抑制</strong>状态。</li><li>大脑的学习过程就是神经元之间连接强度随外部激<br>励信息作自适应变化的过程，大脑处理信息的结果<br>由各神经元状态的整体效果确定。</li><li><strong>神经元</strong>不仅是组成大脑的基本单元，也是<strong>大脑进行信息处理的基本元件</strong>。</li><li>生物神经元的功能<ul><li>时空整合功能。生物神经元可以对同一时刻来自不同神经元的神经冲动进行组合处理，也可以对不同时刻来自同一突触传入的神经冲动进行组合处理。</li><li>兴奋与抑制。兴奋是传入冲动的时空整合结果使得细胞膜电位升高，超过阈值，细胞进入兴奋状态，产生神经冲动；抑制是细胞膜电位低于阈值，细胞进入抑制状态，无神经冲动。</li><li>突触时延和不应期。不应期是在相邻的两次神经冲动间需要时间间隔。在不应期内，突触对任何激励不做相应。</li><li>学习，遗忘和疲劳。</li><li>脉冲与电位转换。</li><li>神经纤维传导。</li></ul></li><li><strong>人工神经元模型</strong>应该具有生物神经元的基本特性。</li><li>激活函数比较：<ul><li>ReLu</li><li>Sigmoid</li></ul></li></ol><h2 id="第三章-感知器"><a href="#第三章-感知器" class="headerlink" title="第三章 感知器"></a>第三章 感知器</h2><ol><li>神经元的状态取决于细胞自身或从其他的神经细胞收到的输入信号量。当输入或者激励信号量总和超过了某个阈值时，细胞体就会产生电脉冲，电脉冲会沿着轴突通过突触传播到其他神经元。</li><li>感知器第一次引入了<strong>学习</strong>的概念，使得人脑具备的功能在数学中得到了一定的模拟。</li><li>简单感知器模型是M-P模型的结构，是一种单层感知器模型，一层为输入层，另一层具有计算单元。</li><li>感知器即单层神经网络，或者叫神经元，是组成神经网络的最小单元。这种神经元模型由一个线性累加器和传递函数单元组成。</li><li>感知器的激活函数采用阶跃函数或符号函数。</li><li>单层感知器只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，其学习能力非<br>常有限，只能用于解决线性可分的问题，不能解决异或问题。</li><li>感知器的局限性：<ul><li>感知器的激活函数是单向阈值函数，感知器网络的输出值只能取0或1；</li><li>感知器只能对线性可分的向量集合进行分类，不能解决异或问题；</li><li>感知器采用纠错学习规则进行学习，当样本中存在奇异样本时，网络训练所花费的时间就很长。</li></ul></li></ol><h2 id="第四章-反向传播（BP）网络"><a href="#第四章-反向传播（BP）网络" class="headerlink" title="第四章 反向传播（BP）网络"></a>第四章 反向传播（BP）网络</h2><ol><li>梯度：函数在自变量x增加时，最大增长率的方向。</li><li>负梯度：函数的最陡峭下降方向。</li><li>损失函数：定义在单个样本上的，是指一个样本的误差。</li><li>代价函数：定义在整个训练集上的，是所有样本误差的平均，也就是所有损失函数值的平均。</li><li>三种梯度下降优化框架<ul><li>批量梯度下降法<ul><li>每次使用全部的训练样本来进行学习</li><li>优点：每次更新都会朝着正确的方向进行，最后能保证收敛于极值点</li><li>缺点：每次学习的时间过长，并且如果训练集很大， 以至于需要消耗大量的内存们不能进行在线模型参数更新。</li></ul></li><li>随机梯度下降法<ul><li>每次从训练集中随机选择一个样本来进行学习</li><li>优点：每次只随机选择一个样本来更新模型参数，因此每次的学习是非常快速的，并可以进行在线更新。</li><li>缺点：每次更新可能不会朝着正确的方向进行，因此会带来优化波动，使得迭代次数增多，即收敛速度变慢。</li></ul></li><li>小批量梯度下降法<ul><li>在每次更新速度与更新次数中间做一个平衡，其每次更新从训练集中随机选择k个样本进行学习</li><li>优点：相对于随机梯度下降，Mini-batch梯度下降降低了收敛波动性，即降低了参数更新的方差，使得更行更加稳定。相对于批量梯度下降，提高了每次学习的速度。不需要担心内存瓶颈。</li></ul></li></ul></li><li>反向传播算法的思想：中间隐层由于不直接与外界连接，误差无法估计。  从后向前反向逐层传播输出层的误差，以间接计算隐层的误差，算法可以分为两个阶段：<ul><li>正向过程：从输入层经隐层逐层正向计算各单元的输出；</li><li>反向过程：由输出误差逐层反向计算隐层个单元的误差，并用此误差修正前层的权值。</li></ul></li></ol><h2 id="第六章-玻尔兹曼机"><a href="#第六章-玻尔兹曼机" class="headerlink" title="第六章 玻尔兹曼机"></a>第六章 玻尔兹曼机</h2><ol><li>玻尔兹曼机是第一个受<strong>统计力学</strong>启发的多层学习机，是一类典型的随机神经网络，属于<strong>反馈神经网络类型</strong>。</li><li>玻尔兹曼机在神经元状态变化中引入了<strong>统计概率</strong>，网络的平衡状态服从玻尔兹曼分布，网络运行机制基于<strong>模拟退火算法</strong>。</li><li>玻尔兹曼机结合多层前馈神经网络和离散Hopfield网络。</li><li>离散Hopfield神经网络+模拟退火+隐单元 = 玻尔兹曼机</li><li>对于BM机，随着网络状态的演变，从概率意义上网络的能量总是朝着减小的方向变化。</li></ol><h2 id="第七章-自组织映射神经网络"><a href="#第七章-自组织映射神经网络" class="headerlink" title="第七章 自组织映射神经网络"></a>第七章 自组织映射神经网络</h2><ol><li>自组织神经网络的典型结构：竞争层与输入层</li><li>自组织神经网络属于竞争性学习网络，包括：<ul><li>输入层起<strong>观察</strong>作用，负责接收外界信息并将输入模式向竞争层传递；</li><li>竞争层起<strong>分析比较</strong>作用，负责找出规律并完成模式归类。各神经元之间的虚线连接线即使模式生物神经网络层内神经元的侧抑制现象。神经细胞一旦兴奋，会对其周围的神经细胞产生<strong>抑制作用</strong>。</li></ul></li><li>自组织学习<ul><li>通过自动寻找样本中的内在规律和本质属性，<strong>自组织、自适应地</strong>改变网络参数与结构。</li><li>自组织网络的自组织功能是通过<strong>竞争学习</strong>实现的。</li><li>分类：在类别知识等导师信号的指导下，将待识别的输入模式分配到各自的模式类中。</li><li>聚类：无导师指导的分类。聚类的目的是将相似的模式样本划归一类，而将不相似的分离开。</li></ul></li><li>相似性测量：余弦法，欧式距离法。</li><li>竞争学习规则：网络的输出神经元之间相互竞争以求被激活，结果在每一时刻只有一个神经元被激活，称为获胜神经元，而其它神经元的状态被抑制，称为胜者为王规则。</li><li>自组织映射的原理：一个神经网络接收外界输入模式时，将会分为不同的对应区域，各区域对输入模式具有不同的相应特征，而且这个过程是自动完成的。</li><li>SOM网采用的学习算法成为Kohonen算法，是在胜者为王算法基础上改进而来的，二者主要的区别在于调整权向量和侧抑制方式不同。<ul><li>侧抑制方式：在胜者为王算法中，只有获胜神经元才有权调整权向量，其他任何神经元都无权调整，因此它对周围所有神经元的抑制是封杀式的。SOM网的获胜神经元对其临近神经元的影响是由近到远，由兴奋转为抑制。</li><li>调整权向量方式：SOM网的学习算法中，不仅获胜神经元本身要调整权向量，其周围的神经元在其影响下也要调整权向量。</li></ul></li><li>神经元的模型确定之后，一个神经网络的特性及能力主要取决于网格以及学习方法。</li><li>在构成多层网络时，层间的转移函数应该是非线性的，否则多层网格的计算能力并不比单层网络强，若干的线性单元层叠加还是线性单元。</li></ol><h2 id="第八章-卷积神经网络"><a href="#第八章-卷积神经网络" class="headerlink" title="第八章 卷积神经网络"></a>第八章 卷积神经网络</h2><ol><li>卷积神经网络(Convolutional Neural Network, CNN)其本质是一个多层感知机，成功的原因在于其所采用的局部连接和权值共享的方式。<ul><li>一方面减少了权值的数量，使得网络易于优化</li><li>另一方面降低了模型的复杂度，减小了过拟合的风险。</li></ul></li><li>卷积操作的核心是：可以约减不必要的权值连接，引入稀疏或者局部连接，带来的权值共享策略大大减少参数量，相对的提升了数据量，从而可以避免过拟合现象的发生。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 考试资料 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LeNet </tag>
            
            <tag> BP神经网络 </tag>
            
            <tag> 感知器 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 玻尔兹曼机 </tag>
            
            <tag> 竞争学习网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《深度学习DeepLearning》</title>
      <link href="2021/01/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(DeepLearning)/"/>
      <url>2021/01/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(DeepLearning)/</url>
      
        <content type="html"><![CDATA[<pre><code> 本文是个人对于图灵异步图书《深度学习》的读书笔记，希望与各位分享，不足之处欢迎提出修改意见</code></pre><h2 id="第一部分-机器学习发展"><a href="#第一部分-机器学习发展" class="headerlink" title="第一部分 机器学习发展"></a>第一部分 机器学习发展</h2><h3 id="一、早期的人工智能"><a href="#一、早期的人工智能" class="headerlink" title="一、早期的人工智能"></a>一、早期的人工智能</h3><ol><li>人工智能早期主要用于解决可以用一系列形式化数学规则来描述的问题。</li><li>这种规则化的系统遇到的主要挑战在于解决对人来说很容易执行，但很难形式化描述的任务。</li><li> 代表实例为知识库方法。知识库是将世界的知识用形式化的语言进行硬解码，从而使计算机可以通过逻辑推理规则来自动理解形式化语言中的声明。其中Cyc项目通过一个推理引擎和Cylc语言声明的数据库就是基于此思想实现的项目。</li><li>早期人工智能最大的弊端在于数据库是由人为输入的，对于复杂的项目来说极为耗费人力，且人类无法设计足够精细化的规则来描述世界。</li></ol><h3 id="二、机器学习（Meachine-Learning）"><a href="#二、机器学习（Meachine-Learning）" class="headerlink" title="二、机器学习（Meachine Learning）"></a>二、机器学习（Meachine Learning）</h3><ol><li>针对无法使用规则化的语言来描述世界，机器学习应运而生。</li><li>机器学习为AI系统自己具备获取知识的能力，即从原始数据中提取模式的能力。它能够解决涉及现实世界知识的问题，并能做出看似主观的决策。</li><li>简单的机器学习算法的性能很大程度上依赖于给定的表示，然而对于很多任务来说，我们很难直到应该提取哪些特征。<h3 id="三、表示学习（Representation-Learning）"><a href="#三、表示学习（Representation-Learning）" class="headerlink" title="三、表示学习（Representation Learning）"></a>三、表示学习（Representation Learning）</h3></li><li>表示学习是指通过机器学习来发掘表示本身，提取出当前任务所需要的表示特征，而不仅仅把表示映射到输出。</li><li>典型实例是自编码器。自编码器包括解码器函数和编码器函数，编码器将输入数据转换为一种不同的表示，编码器将新的表示转换为原来的形式。自编码器的训练目标为新的数据尽可能多地保留信息，并希望有各种好的特性，针对不同的特性可以设计不同的编码器。</li><li>表示学习的优点是学习到的表示往往比手动设计的表示更好，且只需要极少的人工干预。</li><li>表示学习的主要困难来源于多个变差因素同时影响着我们能够观察到的每一个数据，例如在一张包含红色汽车的图片中，其单个像素在夜间可能接近于黑色，汽车的轮廓取决于视角等等。从原始数据中提取高层次、抽象的特征十分困难。<h3 id="四、深度学习（Deep-Learning）"><a href="#四、深度学习（Deep-Learning）" class="headerlink" title="四、深度学习（Deep Learning）"></a>四、深度学习（Deep Learning）</h3></li><li>深度学习通过其他较简单的表示来描述复杂的表示，改善了表示学习。</li><li>深度学习相比较简单的表示学习，有了更抽象特征的额外层。</li><li>衡量模型深度的方式：<br>   一种是架构所需执行的顺序指令的数目。<pre><code>  另一种是将描述概念彼此如何关联的概念图的深度作为模型的深度。</code></pre></li></ol><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><h3 id="深度学习的发展浪潮"><a href="#深度学习的发展浪潮" class="headerlink" title="深度学习的发展浪潮"></a>深度学习的发展浪潮</h3><ol><li><p>20世纪40-60年代，深度学习的雏形初现在控制论中。</p></li><li><p>20世纪80-90年代，深度学习表现为联结主义。</p></li><li><p>直到2006年，真正以深度学习之名复兴。</p><h3 id="深度学习的神经观点"><a href="#深度学习的神经观点" class="headerlink" title="深度学习的神经观点"></a>深度学习的神经观点</h3></li><li><p>深度学习的神经观点受两个主要思想启发：</p><pre><code>一个想法是大脑证明智能行为是可行的，因此建立智能的直接途径是逆向大脑背后的计算原理，并复制其功能。另一种看法是理解大脑和人类智能背后的原理。</code></pre></li><li><p>现代术语“神经网络”超越了目前机器学习模型的神经科学观点，诉诸于多层次组合。这个原理同样适用于那些普通的机器学习框架。</p><h3 id="联结主义"><a href="#联结主义" class="headerlink" title="联结主义"></a>联结主义</h3><p>联结主义的中心思想是网络将大量简单的计算单元链接在一起时，可以实现智能行为。</p></li><li><p>分布式表示：系统 的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。</p></li><li><p>反向传播在训练具有内部表示的深度神经网络中的成功使用及反向传播算法的普及。</p></li></ol><h2 id="第二部分-应用数学与机器学习基础"><a href="#第二部分-应用数学与机器学习基础" class="headerlink" title="第二部分 应用数学与机器学习基础"></a>第二部分 应用数学与机器学习基础</h2>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
